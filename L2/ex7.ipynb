{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "[(18, 215), (26, 7), (0, 3), (1, 3), (60, 3), (2, 0), (3, 0), (4, 0), (5, 0), (6, 0), (7, 0), (8, 0), (9, 0), (10, 0), (11, 0), (12, 0), (13, 0), (14, 0), (15, 0), (16, 0), (17, 0), (19, 0), (20, 0), (21, 0), (22, 0), (23, 0), (24, 0), (25, 0), (27, 0), (28, 0), (29, 0), (30, 0), (31, 0), (32, 0), (33, 0), (34, 0), (35, 0), (36, 0), (37, 0), (38, 0), (39, 0), (40, 0), (41, 0), (42, 0), (43, 0), (44, 0), (45, 0), (46, 0), (47, 0), (48, 0), (49, 0), (50, 0), (51, 0), (52, 0), (53, 0), (54, 0), (55, 0), (56, 0), (57, 0), (58, 0), (59, 0), (61, 0), (62, 0), (63, 0), (64, 0), (65, 0), (66, 0), (67, 0), (68, 0)]\n"
     ]
    }
   ],
   "source": [
    "with open(\"gutenber_bible.txt\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "with open(\"NLTK's list of english stopwords.txt\", encoding='utf-8') as f:\n",
    "    stopwords = [word for line in f for word in line.split()]\n",
    "\n",
    "chapters_raw = raw_text.split(\"\\n\\n\\n\\n\\n\")\n",
    "\n",
    "import re\n",
    "chapters = [re.sub(\"[^a-z0-9]+\", \" \", chapter.lower()).split(\" \") for chapter in chapters_raw]\n",
    "\n",
    "filtered_chapters = [[w for w in chapter if not w in stopwords and len(w) >= 3] for chapter in chapters]\n",
    "\n",
    "n = len(chapters)\n",
    "rng = range(n)\n",
    "\n",
    "TF = []\n",
    "for chapter in filtered_chapters:\n",
    "    count = {}\n",
    "    for word in chapter:\n",
    "        if word not in count:\n",
    "            count[word] = 1\n",
    "        else:\n",
    "            count[word] += 1\n",
    "    TF.append(count)\n",
    "\n",
    "TFIDFs = []\n",
    "\n",
    "import math\n",
    "for i,chapter in enumerate(filtered_chapters):\n",
    "    print(i)\n",
    "    TFIDF = {}\n",
    "    for word in chapter:\n",
    "        k = 0\n",
    "        for chapter in filtered_chapters:\n",
    "            if word in chapter:\n",
    "                k += 1\n",
    "        IDF = math.log2(n/k)\n",
    "        TFIDF[word] = int(TF[i][word] * IDF)\n",
    "\n",
    "    TFIDFs.append(TFIDF)\n",
    "\n",
    "def chapters_for_word(word, TFIDF_list):\n",
    "    ranking = []\n",
    "    for i in range(len(TFIDF_list)):\n",
    "        if word not in TFIDF_list[i].keys():\n",
    "            ranking.append((i,0))\n",
    "        else:\n",
    "            ranking.append((i,TFIDF_list[i][word]))\n",
    "    ranking.sort(reverse=True, key=lambda pair: pair[1])\n",
    "    return ranking\n",
    "\n",
    "print(chapters_for_word('job', TFIDFs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
